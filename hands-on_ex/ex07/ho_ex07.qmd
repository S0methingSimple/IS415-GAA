---
title: "Hands-on Exercise 7"
author: "Jeffery Lau"
date: 10-11-2024
date-modified: "last-modified"
description: |
  In this exercise we discorver geopgraphical segmentation with spatially constrainted clustering techniques
categories:
  - Hands-on
format:
  html:
    toc: true
execute: 
  eval: true
  echo: true
  warning: false
  freeze: true
---

# 1. Overview

This hands-on exercise we are aiming to identify distinct areas within Shan State, Myanmar based on their similarities in Information and Communication Technology (ICT) usage. We will utilize data on various ICT measures, including radio, television, landline phones, mobile phones, computers, and home internet, to delineate these homogeneous regions. This analysis will help us understand the spatial distribution of ICT infrastructure and usage patterns across the state.

# 2. Setup

## 2.1 Loading Packages

1.   Spatial data handling: sf, rgdal and spdep
2.   Multivariate data analysis: coorplot, ggpubr, and heatmaply
3.   Cluster analysis: cluster, ClustGeo

```{r}
pacman::p_load(spdep, tmap, sf, ClustGeo, 
               ggpubr, cluster, factoextra, NbClust,
               heatmaply, corrplot, psych, tidyverse, GGally)
```

## 2.2 Importing Data

```{r}
# Import shan boundary map
shan_sf <- st_read(dsn = "data/geospatial", 
                   layer = "myanmar_township_boundaries") %>%
  filter(ST %in% c("Shan (East)", "Shan (North)", "Shan (South)")) %>%
  select(c(2:7))

head(shan_sf)
```

```{r}
# Import 2014 Myanmar Population and Housing Census Myanmar.  
ict <- read_csv ("data/aspatial/Shan-ICT.csv")
summary(ict)
```

## 2.3 Data Wrangling

We will be re-scaling the unit of measurement as they are per household and some townships may have higher total number of household, which may introduces bias.

```{r}
ict_derived <- ict %>%
  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %>%
  mutate(`TV_PR` = `Television`/`Total households`*1000) %>%
  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %>%
  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %>%
  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %>%
  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %>%
  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,
         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,
         `TT_HOUSEHOLDS`=`Total households`,
         `RADIO`=`Radio`, `TV`=`Television`, 
         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,
         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) 
```

```{r}
summary(ict_derived)
```

# 3. Exploratory Data Analysis (EDA)

## 3.1 Staistical Graphs

### 3.1.1 Histogram

```{r}
ggplot(data=ict_derived, 
       aes(x=`RADIO`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")
```

### 3.1.2 Boxplot

```{r}
ggplot(data=ict_derived, 
       aes(x=`RADIO`)) +
  geom_boxplot(color="black", 
               fill="light blue")
```

### 3.1.3 Overview of Normalized Data

```{r}
radio <- ggplot(data=ict_derived, 
             aes(x= `RADIO_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

tv <- ggplot(data=ict_derived, 
             aes(x= `TV_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

llphone <- ggplot(data=ict_derived, 
             aes(x= `LLPHONE_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

mphone <- ggplot(data=ict_derived, 
             aes(x= `MPHONE_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

computer <- ggplot(data=ict_derived, 
             aes(x= `COMPUTER_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

internet <- ggplot(data=ict_derived, 
             aes(x= `INTERNET_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

ggarrange(radio, tv, llphone, mphone, computer, internet, 
          ncol = 3, 
          nrow = 2)
```

## 3.2 Chloropleth Maps

Next we join the shan_sf with the ict data, save in rds

```{r}
shan_sf <- left_join(shan_sf, 
                     ict_derived, by=c("TS_PCODE"="TS_PCODE"))
  
write_rds(shan_sf, "data/rds/shan_sf.rds")
```

```{r}
shan_sf <- read_rds("data/rds/shan_sf.rds")
```

Notice the difference in the normalized (PR) vs original data: It seems more normally distributed with less variance

```{r}
tm_shape(shan_sf) +
    tm_polygons(c("TT_HOUSEHOLDS", "RADIO", "RADIO_PR"),
                style="jenks") +
    tm_facets(sync = TRUE, ncol = 3) +
  tm_legend(legend.position = c("right", "bottom"))+
  tm_layout(outer.margins=0, asp=0)
```

## 3.3 Correlation Analysis

The correlation plot shows that COMPUTER_PR and INTERNET_PR are highly correlated. This suggest that only one of them should be used in the cluster analysis instead of both.

```{r}
cluster_vars.cor = cor(ict_derived[,12:17])
corrplot.mixed(cluster_vars.cor,
         lower = "ellipse", 
               upper = "number",
               tl.pos = "lt",
               diag = "l",
               tl.col = "black")
```

# 4. Hierarchy Cluster Analysis

## 4.1 Extracting clustering variables

We will be filtering for just variables that are not highly correlated

```{r}
cluster_vars <- shan_sf %>%
  st_set_geometry(NULL) %>%
  select("TS.x", "RADIO_PR", "TV_PR", "LLPHONE_PR", "MPHONE_PR", "COMPUTER_PR")
head(cluster_vars,10)
```

Use township name as row index instead of number

```{r}
row.names(cluster_vars) <- cluster_vars$"TS.x"
shan_ict <- select(cluster_vars, c(2:6))
head(shan_ict,10)
```

## 4.2 Data Standardisation

### 4.2.1 Min Max

It is a data standardization technique that rescales features to a specific range, typically between 0 and 1. It involves subtracting the minimum value from each data point and then dividing by the range (maximum minus minimum). This method is useful when preserving the relative relationships between values is important, such as in algorithms that rely on distance calculations. However, it can be sensitive to outliers, as they can significantly impact the range of the data.

```{r}
shan_ict.std <- normalize(shan_ict)
summary(shan_ict.std)
```

### 4.2.2 Z-score 

It is another data standardization technique that transforms features to have a mean of 0 and a standard deviation of 1. It involves subtracting the mean from each data point and then dividing by the standard deviation. This method is useful when dealing with algorithms that assume **normally distributed data**, as it helps to ensure that the data is centered around 0 and has a consistent scale. Z-score standardization is less sensitive to outliers than min-max scaling, as outliers are scaled based on their distance from the mean. 

```{r}
shan_ict.z <- scale(shan_ict)
describe(shan_ict.z)
```

## 4.3 Visualisaing Standardised Clustering Variables

With standardization the data are confined within a range while preseving the relative relationships between values

```{r}
r <- ggplot(data=ict_derived, 
             aes(x= `RADIO_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  ggtitle("Raw values without standardisation")

shan_ict_s_df <- as.data.frame(shan_ict.std)
s <- ggplot(data=shan_ict_s_df, 
       aes(x=`RADIO_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  ggtitle("Min-Max Standardisation")

shan_ict_z_df <- as.data.frame(shan_ict.z)
z <- ggplot(data=shan_ict_z_df, 
       aes(x=`RADIO_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  ggtitle("Z-score Standardisation")

ggarrange(r, s, z,
          ncol = 3,
          nrow = 1)
```

```{r}
r <- ggplot(data=ict_derived, 
             aes(x= `RADIO_PR`)) +
  geom_density(color="black",
               fill="light blue") +
  ggtitle("Raw values without standardisation")

shan_ict_s_df <- as.data.frame(shan_ict.std)
s <- ggplot(data=shan_ict_s_df, 
       aes(x=`RADIO_PR`)) +
  geom_density(color="black",
               fill="light blue") +
  ggtitle("Min-Max Standardisation")

shan_ict_z_df <- as.data.frame(shan_ict.z)
z <- ggplot(data=shan_ict_z_df, 
       aes(x=`RADIO_PR`)) +
  geom_density(color="black",
               fill="light blue") +
  ggtitle("Z-score Standardisation")

ggarrange(r, s, z,
          ncol = 3,
          nrow = 1)
```

## 4.4 Computing Proximity Matrix

using `dist` we can plotcompute the distance matrix. 6 calculations are supported: euclidean, maximum, manhattan, canberra, binary and minkowski. The default is euclidean proximity matrix.

```{r}
proxmat <- dist(shan_ict, method = 'euclidean')
proxmat
```

## 4.5 Computing Hierarchical Clustering

Using `hclust` which employs agglomeration method to compute the cluster. Supports: ward.D, ward.D2, single, complete, average (UPGMA), mcquitty (WPGMA), median (WPGMC) and centroid (UPGMC)

```{r}
hclust_ward <- hclust(proxmat, method = 'ward.D')
```

We can view the cluster in a tree format

```{r}
plot(hclust_ward, cex = 0.6)
```

## 4.6 Selecting Optimal Clustering Algorithm

Using `agnes` we can find the optimal clustering structure

```{r}
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")

ac <- function(x) {
  agnes(shan_ict, method = x)$ac
}

map_dbl(m, ac)
```

From the above we can see that Ward’s method provides the strongest clustering structure. Hence, in the subsequent analysis, only Ward’s method will be used.

## 4.7 Determining Optimal Clusters

There are three commonly used methods: Elbow, Average Silhouette and Gap Statistic

### 4.7.1 Gap statistic method

This method compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The clustering structure is far from the random uniform distribution of points.

```{r}
set.seed(12345)
gap_stat <- clusGap(shan_ict, 
                    FUN = hcut, 
                    nstart = 25, 
                    K.max = 10, 
                    B = 50)

print(gap_stat, method = "firstmax")
```

This can be visualized with `fviz_gap_stat`. According to graph the number of cluster to retain is 1. 

```{r}
fviz_gap_stat(gap_stat)
```

### 4.7.2 Interpreting the dendrograms

In Dendogram we can see each observation are combined into branches which are grouped by borders with hclust.

```{r}
plot(hclust_ward, cex = 0.6)
rect.hclust(hclust_ward, 
            k = 6, 
            border = 2:5)
```

## 4.8 Visually-Driven Hierarchical Clustering Analysis

Using `heatmaply` we are able to build interactive cluster heatmap

```{r}
shan_ict_mat <- data.matrix(shan_ict)
```

Plot an interactive cluster heatmap

```{r}
heatmaply(normalize(shan_ict_mat),
          Colv=NA,
          dist_method = "euclidean",
          hclust_method = "ward.D",
          seriate = "OLO",
          colors = Blues,
          k_row = 6,
          margins = c(NA,200,60,NA),
          fontsize_row = 4,
          fontsize_col = 5,
          main="Geographic Segmentation of Shan State by ICT indicators",
          xlab = "ICT Indicators",
          ylab = "Townships of Shan State"
          )
```

## 4.9 Mapping the formed clusters

Using `cutree` to derive of 6-cluster

```{r}
groups <- as.factor(cutree(hclust_ward, k=6))
```

Append shan_sf spatial features with the groups

```{r}
shan_sf_cluster <- cbind(shan_sf, as.matrix(groups)) %>%
  rename(`CLUSTER`=`as.matrix.groups.`)
```

We can use `qtm` to view the clusters. The clusters are very fragmented, which is a result of using non-spatial clustering algorithm

```{r}
qtm(shan_sf_cluster, "CLUSTER")
```

# 5. Spatially Constrained Clustering: SKATER

## 5.1 Convert and Compute Neighbors

Here we convert the shan_sf to SpatialPolygonsDataFrame and compute the neighbor.

```{r}
shan_sp <- as_Spatial(shan_sf)
shan.nb <- poly2nb(shan_sp)
summary(shan.nb)
```

Visualize the neighbours

```{r}
sp::plot(shan_sp, 
     border=grey(.5))
plot(shan.nb, 
     sp::coordinates(shan_sp), 
     col="blue", 
     add=TRUE)
```

## 5.2 Computing Minimum Spanning Tree

Using `nbcosts` we can compute the cost of each edge

```{r}
lcosts <- nbcosts(shan.nb, shan_ict)
```

Using the the B style we ensure the cost values are not row-standardised

```{r}
shan.w <- nb2listw(shan.nb, 
                   lcosts, 
                   style="B")
summary(shan.w)
```

Using the `mstree` we can compute the MST using the mean

```{r}
shan.mst <- mstree(shan.w)
class(shan.mst)
head(shan.mst)
```

MST dimension is n-1 edges, hence 54 instead of 55

```{r}
dim(shan.mst)
```

Plot the MST

```{r}
sp::plot(shan_sp, border=gray(.5))
plot.mst(shan.mst, 
         sp::coordinates(shan_sp), 
         col="blue", 
         cex.lab=0.7, 
         cex.circles=0.005, 
         add=TRUE)
```

## 5.4 Computing spatially constrained clusters using SKATER method

Using `skater` we can compute the spatially constrained cluster 

```{r}
clust6 <- spdep::skater(edges = shan.mst[,1:2], 
                 data = shan_ict, 
                 method = "euclidean", 
                 ncuts = 5)
str(clust6)
```

Because the labels of the cluster to which each observation belongs is computed we can check cluster assignment

```{r}
ccs6 <- clust6$groups
ccs6
```

We can see how many observations in each cluster

```{r}
table(ccs6)
```

Plot the pruned tree that shows the five clusters on top of the township area

```{r}
sp::plot(shan_sp, border=gray(.5))
plot(clust6, 
     sp::coordinates(shan_sp), 
     cex.lab=.7,
     groups.colors=c("red","green","blue", "brown", "pink"),
     cex.circles=0.005, 
     add=TRUE)
```

## 5.5 Visualising the New Clusters

The skater derived new cluster, seems much more spatially coherent

```{r}
groups_mat <- as.matrix(clust6$groups)
shan_sf_spatialcluster <- cbind(shan_sf_cluster, as.factor(groups_mat)) %>%
  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)

hclust.map <- qtm(shan_sf_cluster,
                  "CLUSTER") + 
  tm_borders(alpha = 0.5) 

shclust.map <- qtm(shan_sf_spatialcluster,
                   "SP_CLUSTER") + 
  tm_borders(alpha = 0.5) 

tmap_arrange(hclust.map, shclust.map,
             asp=NA, ncol=2)
```

## 5.6 Spatially Constrained Clustering: ClustGeo Method

Next we will be using the `ClustGeo` package to perform non-spatially constrained hierarchical cluster analysis and spatially constrained cluster analysis

### 5.6.1 Non-geographically constrained clusters

We can use the `hclustgeo` to perform a typical Ward-like hierarchical clustering just like `hclust`

```{r}
nongeo_cluster <- hclustgeo(proxmat)
plot(nongeo_cluster, cex = 0.5)
rect.hclust(nongeo_cluster, 
            k = 6, 
            border = 2:5)
```

### 5.6.2 Mapping the cluster

```{r}
groups <- as.factor(cutree(nongeo_cluster, k=6))

shan_sf_ngeo_cluster <- cbind(shan_sf, as.matrix(groups)) %>%
  rename(`CLUSTER` = `as.matrix.groups.`)

qtm(shan_sf_ngeo_cluster, "CLUSTER")
```

## 5.7 Spatially Constrainted Hierarchical Clustering

We need the spatial distance matrix we can perform spatially constrained hierarchical clustering

```{r}
dist <- st_distance(shan_sf, shan_sf)
distmat <- as.dist(dist)
```

Using `choicealpha` will be used to determine a suitable value for the mixing parameter alpha as shown in the code chunk below. 

```{r}
cr <- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=6, graph = TRUE)
```


Next we perform the clustering and we will be using 0.2 for alpha with the above graph 

```{r}
clustG <- hclustgeo(proxmat, distmat, alpha = 0.2)
```

Using `cutree` we derive our cluster object

```{r}
groups <- as.factor(cutree(clustG, k=6))
```

Join with shan_sf for spatial attibute.

```{r}
shan_sf_Gcluster <- cbind(shan_sf, as.matrix(groups)) %>%
  rename(`CLUSTER` = `as.matrix.groups.`)
```

We can now view the plot

```{r}
qtm(shan_sf_Gcluster, "CLUSTER")
```

# 6. Visual Interpretation of Clusters

Boxplot reveals Cluster 3 displays highest mean Radio Ownership per 1000 household. Followed by 2, 1, 4, 6, 5

```{r}
ggplot(data = shan_sf_ngeo_cluster,
       aes(x = CLUSTER, y = RADIO_PR)) +
  geom_boxplot()
```

### 6.1 Multivariate Visualisation

We can also use `ggparacoord` to perform parallel coordinate plot to reveal the households ownership across the clusters. (Why does 4 have higher RADIO PR than 3?)

```{r}
ggparcoord(data = shan_sf_ngeo_cluster, 
           columns = c(17:21), 
           scale = "globalminmax",
           alphaLines = 0.2,
           boxplot = TRUE, 
           title = "Multiple Parallel Coordinates Plots of ICT Variables by Cluster") +
  facet_grid(~ CLUSTER) + 
  theme(axis.text.x = element_text(angle = 30))
```

Finally we can also compute the summary statistics such as mean, median, sd, etc to complement the visual interpretation.

```{r}
shan_sf_ngeo_cluster %>% 
  st_set_geometry(NULL) %>%
  group_by(CLUSTER) %>%
  summarise(mean_RADIO_PR = mean(RADIO_PR),
            mean_TV_PR = mean(TV_PR),
            mean_LLPHONE_PR = mean(LLPHONE_PR),
            mean_MPHONE_PR = mean(MPHONE_PR),
            mean_COMPUTER_PR = mean(COMPUTER_PR))
```
